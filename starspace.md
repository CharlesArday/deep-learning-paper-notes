* StarSpace: Embed All The Things! [[link](http://arxiv.org/abs/1709.03856)] [[notes](starspace.md)]


## [StarSpace: Embed All The Things!](http://arxiv.org/abs/1709.03856)

_Sep 2017_

tl;dr:

#### Key ideas

*

#### Notes/Questions

*

#### Related Work

Unsupervised embeddings:
* Joulin et al., 2016: Bag of tricks for efficient text classification. _Simple text classification tasks might just require averaging simple word representations together (instead of a deeper approach). _.
* Conneau et al., 2017: Supervised learning of universal sentence representations from natural language inference data: __.
Supervised embeddings:
* SSI; Bai et al., 2009: Supervised semantic indexing. __.
* Weston, Bengio, and Usunier, 2011: Wsabie: Scaling up to large vocabulary image annotation. __.
* Tang, Qin, and Liu, 2015: Document modeling with gated recurrent neural network for sentiment classification. __.
* Zhang and LeCun, 2015: Text understanding from scratch. __.
* Conneau et al., 2016: Very deep convolutional networks for natural language processing. __.
* TagSpace; Weston, Chopra, and Adams, 2014: #tagspace: Semantic embeddings from hashtags. __.
